\section{Precorso}

\subsection{Base di uno spazio vettoriale}
  Oltre alla definizione solita data in algebra lineare, esiste una definizione più astratta di base di uno spazio vettoriale.
  \begin{mydef}
    Sia $V$ uno spazio vettoriale. Si dice \emph{base} di $V$ un insieme di indici $I$ con un'applicazione $e: I \rar V$ se per ogni $W$ spazio vettoriale e per ogni $f: I \rar W$, esiste un'unica $\phi: V \rar W$ lineare tale che il seguente diagramma commuta

    	\tridiag IeV\phi Wf

  \end{mydef}

  \begin{myprop}
    Sono fatti equivalenti:
    \begin{enumerate}
    \item $e: I \rar V$ è una base;
    \item Ogni $v \in V$ si scrive \emph{in modo unico} come $\sum_i a_ie_i$ con $a: I\rar V$ a supporto finito. 
    \end{enumerate}
  \end{myprop}
  \begin{proof}
    Dimostriamo le due implicazioni.
    \begin{itemize}
      \item $2\Rar 1$
      
      Se una tale $\phi$ esiste, allora deve essere $\phi(v)=\phi(\sum_i a_i e_i) = \sum a_i \phi(e_i) = \sum a_i f_i$. D'altra parte questa $\phi$ funziona.
      
      \item $1 \Rar 2$
      
      Considero $W = \{\sum_i a_ie_i : a:I\rar \bC \mbox{ a supporto finito}\}$. $W$ è un sottospazio di $V$ e vale ovviamente che $\im e \subseteq W$. Sia ora $\pi$ una proiezione sul quoziente $V/W$, e sia $f: I \rar V/W$ l'applicazione nulla.
	
	\tridiag IeV\pi{V/W}f
      
      Il diagramma sopra commuta, dato che $\im e \subseteq W$. Ma commuta anche se al posto di $\pi$ metto l'applicazione nulla. Quindi per l'unicità data dalla definizione di base $V/W$ deve essere banale, cioè $V=W$.
    \end{itemize}
  \end{proof}
  
\subsection{Moduli}
  \begin{mydef}
    Sia $A$ un anello commutativo con identità. Si dice $A$-modulo un gruppo abeliano additivo $(M,+)$ con un'operazione $\cdot: A\times M \rar M$ distributiva da entrambe le parti, associativa e tale che $1_A \cdot x = x$.
  \end{mydef}
  
  Un modulo non è altro che la generalizzazione di uno spazio vettoriale, dove gli scalari non sono più un campo ma bensì un anello.
  
  In questo corso la nozione di modulo sarà data solo su anelli della seguente forma.
  \begin{mydef}
    Sia $G$ un gruppo. Si indica con $\bC[G]$ l'anello formato dalle combinazioni lineari formali a coefficienti complessi degli elementi di $G$, ossia gli elementi della forma $\sum_i a_ig_i$ dove la somma è definita in modo ovvio e il prodotto coincide con quello del gruppo, esteso in modo che sia distributivo. 
  \end{mydef}
  
  Un $\bC[G]$-modulo lo possiamo quindi pensare moralmente come un $\bC$-spazio vettoriale dove oltre a una moltiplicazione per uno scalare complesso posso anche moltiplicare per un elemento del gruppo $G$ (sarà tutto più chiaro -- forse -- quando introdurremo il concetto di rappresentazione).

\subsection{Prodotto tensore}
  \begin{mydef}[Prodotto tensore]
    Siano $V, W$ due $\bK$-spazi vettoriali. Si dice \emph{prodotto tensore} di $V$ e $W$, e si indica come $V\tensor W$, uno spazio vettoriale con una funzione bilineare $\tensor: V \times W \rar V\tensor W$ tale che per ogni applicazione bilineare $f: V\times W \rar Z$ esiste un'unica applicazione lineare $\phi: V\tensor W \rar Z$ che fa commutare il seguente diagramma:
    
      \tridiag{V\times W}{ \tensor }{V\tensor W}{\phi}{Z}{f}
  
  \end{mydef}
  
  Bisognerebbe dimostrare che sta roba esiste, ma adesso non ho sbatty.

  Si può dimostrare che se $I \xrar v V$ è una base di $V$, e $J \xrar w W$ è una base di $W$, allora $(i,j) \mapsto v_i \tensor w_i$ è una base di $V\tensor W$.

  \begin{mydef}[Prodotto tensore di applicazioni lineari]
    Si può riportare la definizione di prodotto tensore alle applicazioni lineari. Date $f:V \rar V', g: W \rar W'$, si definisce $f\tensor g: V\tensor W \rar V'\tensor W'$ come
      \[
	(f \otimes g)(v\otimes w)=f(v)\otimes g(w) 
      \]
    
    Il prodotto tensore tra applicazioni fa commutare il seguente diagramma:
    
      \quaddiag{V\times W}{f\times g}{V'\times W'}{}{V'\tensor W'}{}{V \tensor W}{f\tensor g}   
   
   \end{mydef}

  \begin{myobs}
   Nella costruzione del prodotto tensore, noi vorremmo costruire uno spazio che ha per base il prodotto cartesiano delle basi. Tuttavia, non riesco a dotare il prodotto cartesiano della struttura di spazio vettoriale.
   
   Infatti se voglio che l'applicazione $\tensor$ sia bilineare, allora vale che $0 \tensor w = v \tensor 0 = 0$, quindi l'applicazione non è iniettiva, ma non è neanche suriettiva e in generale esistono elementi che non sono della forma $v \tensor w$, ma sono combinazioni lineari di elementi di questa forma.
  \end{myobs}
  \begin{myexample}
  
   Ad esempio, in $\bC \tensor \bC$ come spazi vettoriali su $\bR$, l'elemento $1 \tensor i + i \tensor 1$ non è della forma $v\tensor w$: altrimenti innanzitutto avremmo $v=w$ per simmetria, e scrivendo tutto nella base canonica ottengo, ponendo $v=a+bi$
   \[
    v\tensor v= (a+bi)\tensor (a+bi) = a^2(1\tensor 1) + b^2 (i\tensor i) + ab(i\tensor 1 +1\tensor i)
   \]
   da cui per le proprietà della base su $\bC\tensor \bC$ ottengo $a^2=b^2=0, ab=1$ assurdo.

  \end{myexample}
  
  La potenza tensoriale $V^{\tensor n}$ si definisce nel modo ovvio. Introduciamo ora invece la potenza simmetrica e la potenza esterna.
   
  \begin{mydef}[Potenza simmetrica]
   Indichiamo con $V^n$ il prodotto cartesiano $\overbrace{V \times V \times \dots \times V}^{n \textrm{ volte}}$.
   
   Si dice \emph{potenza simmetrica} $n$-esima di uno spazio vettoriale $V$ uno spazio vettoriale $S^nV$ con un'applicazione multilineare $\sigma$ da $V^n$ a $S^nV$ che sia simmetrica, ossia invariante per permutazione delle entrate, e tale che per ogni altro $Z$ con un'applicazione lineare $\theta: V^n \rar Z$ simmetrica esiste un'unica $\phi: S^n \rar Z$ che fa commutare 
   
      \tridiag{V^n}{\sigma}{S^nV}{\exists!\phi}{Z}{\theta}
  
  \end{mydef}

  \begin{myobs}
   Possiamo pensare la potenza simmetrica come un sottospazio di $V^{\tensor n}$, e più precisamente come il sottospazio invariante per permutazione delle coordinate. Detto meglio, su $V^{\tensor n}$ possiamo far agire il gruppo simmetrico $S_n$ per permutazione, ossia in modo che $v_1 \tensor \dots \tensor v_n \xmapsto{\sigma} v_{\sigma(1)} \dots v_{\sigma(n)}$. Non ho ancora definito ovunque l'azione (perché non tutto si scrive nella forma $v \tensor w$) ma si estende in un unico modo per linearità. La potenza simmetrica è lo spazio lasciato fisso da $S_n$.
  \end{myobs}

  \begin{proof}
   Basta considerare la mappa $(v_1,\dots,v_n) \mapsto \sum_{\sigma \in S_n} v_{\sigma(1)} \dots v_{\sigma(n)}$, e notare che l'immagine è proprio quella cercata dentro $S_n$ e usare la definizione di prodotto tensore per mostrare che quella è $S^nV$.
  \end{proof}
  
  \begin{mydef}[Potenza alternante]
   Si dice \emph{potenza esterna} $n$-esima di uno spazio vettoriale $V$ uno spazio vettoriale $\Lambda^nV$ con un'applicazione multilineare $\wedge$ da $V^n$ a $\Lambda^nV$ che sia stavolta alternante, che significa che $\sigma$ deve cambiare segno se scambio due entrate, e tale che per ogni altro $Z$ con un'applicazione lineare $\theta: V^n \rar Z$ alternante esiste un'unica $\phi: \Lambda^n \rar Z$ che fa commutare 
   
      \tridiag{V^n}{\wedge}{\Lambda^nV}{\exists!\phi}{Z}{\theta}
  
  \end{mydef}
    
  \begin{myobs}
   Per immaginarci la potenza esterna, possiamo pensare a una sorta di potenza tensoriale in cui usiamo il simbolo $\wedge$ al posto del simbolo $\tensor$, e in cui vale la regola aggiuntiva che scambiando due entrate il prodotto deve cambiare segno. Ad esempio, $\Lambda^3V$ sarà formato dalle combinazioni lineari di vettori della forma $a\wedge b \wedge c$. 
   
   Notiamo inoltre che per la regola sopra citata, se un prodotto ha due componenti uguali allora deve essere nullo. Questo è un modo alternativo per definire la potenza esterna.
  \end{myobs}
  
  \begin{myprop}
   La potenza esterna $\Lambda^nV$ è isomorfa a $V^{\tensor n}/W$, dove $W=\Span\{v_1 \tensor \dots \tensor v_n: \exists i,j\quad v_i=v_j\}$.
  \end{myprop}
