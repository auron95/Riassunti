\documentclass[a4paper,10pt,oneside]{math_article}

\newcommand{\Cyc}{\mathbb Z}
\renewcommand{\phi}{\varphi}
%\renewcommand{\Phi}{\varPhi}
\newcommand{\herm}[2]{\left(#1 | #2\right)}
\newcommand{\id}{I}
\newcommand{\class}[1]{\mathbb C[#1]^#1}
\newcommand{\tensor}{\otimes}
\renewcommand{\bar}{\overline}
\DeclareMathOperator{\Reg}{R}

\let\conj\overline
\title{Riassunto di Elementi di Teoria delle Rappresentazioni}
 \author{Matteo Migliorini}
 
\date{}
 
 
\begin{document}
 
 
 \maketitle
 
 \cleardoublepage	
 \tableofcontents
 \cleardoublepage
 
  \section*{Introduzione}
   Questo file è un riassunto del corso dei proff. Angelo Vistoli e Gandini. Tuttavia tenete presente che tutte le cose di Algebra 1 o inferiori verranno date per note (magari verranno \TeX ate in seguito, ma non sperateci troppo).
   
   Inoltre la struttura degli argomenti è ripresa dal Serre, e integrata con gli appunti del corso (per i quali ringraziamo Balbo e Clara).

   \subsection*{DISCLAIMER}
    Il file non è ancora completo, usatelo a vostro rischio e pericolo.
  \section{Precorso}
    \subsection{Base di uno spazio vettoriale}
      Oltre alla definizione solita data in algebra lineare, esiste una definizione più astratta di base di uno spazio vettoriale.
      \begin{mydef}
       Sia $V$ uno spazio vettoriale. Si dice \emph{base} di $V$ un insieme di indici $I$ con un'applicazione $e: I \rar V$ se per ogni $W$ spazio vettroriale e per ogni $f: I \rar W$, esiste un unica $\phi: V \rar W$ lineare tale che il seguente diagramma commuta
       \[
        \begin{diagram}
         I & \rTo^e  & V \\
           & \rdTo_f & \dTo>{\phi}   \\
           &         & W
        \end{diagram}
       \]
      \end{mydef}

      \begin{myprop}
       Sono fatti equivalenti:
       \begin{enumerate}
        \item $e: I \rar V$ è una base;
        \item Ogni $v \in V$ si scrive come $\sum_i a_ie_i$ con $a: I\rar V$ a supporto finito. 
       \end{enumerate}
      \end{myprop}
      \begin{proof}
        Dimostriamo le due implicazioni.
        \begin{itemize}
         \item $2\Rar 1$
	  
	  Se una tale $\phi$ esiste, allora deve essere $\phi(v)=\phi(\sum_i a_i e_i) = \sum a_i \phi(e_i) = \sum a_i f_i$. D'altra parte questa $\phi$ funziona.
	 
         \item $1 \Rar 2$
         
	  Considero $W = \{\sum_i a_ie_i : a:I\rar \bC \mbox{ a supporto finito}\}$. $W$ è un sottospazio di $V$ e vale ovviamente che $\im e \subseteq W$. Sia ora $\pi$ una proiezione sul quoziente $V/W$, e sia $f: I \rar V/W$ l'applicazione nulla.
	    \[
	      \begin{diagram}
	      I & \rTo^e  & V \\
		& \rdTo_f & \dTo>{\pi}   \\
		&         & V/W
	      \end{diagram}
	    \]
	  Il diagramma sopra commuta, dato che $\im e \subseteq W$. Ma commuta anche se al posto di $\pi$ metto l'applicazione nulla. Quindi per l'unicità data dalla definizione di base $V/W$ deve essere banale, cioè $V=W$.
        \end{itemize}
      \end{proof}
     
    \subsection{Moduli}
      \begin{mydef}
       Sia $A$ un anello commutativo con identità. Si dice $A$-modulo un gruppo abeliano additivo $(M,+)$ con un operazione $\cdot: A\times M \rar M$ distributiva da entrambe le parti, associativa e tale che $1_A \cdot x = x$.
      \end{mydef}
      
      Un modulo non è altro che la generalizzazione di uno spazio vettroriale, dove gli scalari non sono più un campo ma bensì un anello.
      
      In questo corso la nozione di modulo sarà data solo su anelli della seguente forma.
      \begin{mydef}
       Sia $G$ un gruppo. Si indica con $\bC[G]$ l'anello formato dalle combinazioni lineari formali a coefficienti complessi degli elementi di $G$, ossia gli elementi della forma $\sum_i a_ig_i$ dove la somma è deifinita in modo ovvio e il prodotto coincide con quello del gruppo, esteso in modo che sia distributivo. 
      \end{mydef}
      
      Un $\bC[G]$-modulo lo possiamo quindi pensare moralmente come un $\bC$-spazio vettoriale dove oltre a una moltiplicazione per uno scalare complesso posso anche moltiplicare per un elemento del gruppo $G$ (sarà tutto più chiaro -- forse -- quando introdiceremo il concetto di rappresentazione).

    \subsection{Prodotto tensore}
      \begin{mydef}[Prodotto tensore]
       Siano $V, W$ due $\bK$-spazi vettoriali. Si dice \emph{prodotto tensore} di $V$ e $W$, e si indica come $V\tensor W$, uno spazio vettoriale con una funzione $\tensor: V \times W \rar V\tensor W$ tale che per ogni applicazione bilineare $f: V\times W \rar Z$ esiste un unica applicazione lineare $\phi: V\tensor W \rar Z$ che fa commutare il seguente diagramma:
	\[
	  \begin{diagram}
	  V\times W & \rTo^\tensor  & V\tensor W \\
	    & \rdTo_f & \dTo>{\phi}   \\
	    &         & Z
	  \end{diagram}
	\]
      \end{mydef}
      
      Bisognerebbe dimostrare che sta roba esiste, ma adesso non ho sbatty.

      
    
    
    \begin{itemize}
     \item Potenza esterna e simmetrica
    \end{itemize}

    
    
    \begin{mydef}[Prodotto tensore]
     Dati due spazi vettoriali sul medesimo campo $V$ e $W$, si dice \myname{prodotto tensore} uno spazio $Z$ con una mappa $(v,w) \mapsto v\cdot w$ da $V\times W$ in $Z$ che sia bilineare e tale che se $(v_i)_{i\in I}$ e $(w_j)_{j\in J}$ sono una base di $V$ e $W$, allora $(v_i\cdot w_j)_{(i,j)\in I\times J}$ è una base di $Z$.
    \end{mydef}
  
    Definiamo inoltre il prodotto tensore di applicazioni lineari come 
    \[
     (f \otimes g)(v\otimes w)=f(v)\otimes g(w) 
    \]
    
      \[
       \begin{diagram}
	V\times W      & \rTo^{f\times g} & V'\times W'\\
	\dTo           &           	  & \dTo \\
	V \tensor W     & \rTo^{f\tensor g}& V'\tensor W'
       \end{diagram}
      \]
   
    TODO: prodotto in forma matricale

  \section{Rappresentazioni}
    \begin{mydef}
      Sia $G$ un gruppo finito, e sia $V$ un $\mathbb C$-spazio vettoriale. Si dice \myname{rappresentazione} di $G$ su $V$ un'azione lineare di $G$ su $V$, ovvero un omomorfismo da $G$ in $GL(V)$.
    \end{mydef}
    
    Le rappresentazioni si possono indicare equivalentemente come delle applicazioni $G \times V \rightarrow V$ con $(g,v)\mapsto gv$, con $gv$ lineare, oppure come mappe $g \mapsto \rho(g)$, dove $\rho(g) \in GL(V)$. In generale mi piace di più il secondo modo. A volte userò anche la notazione $g \mapsto \rho_g$, per evitare quintali di parentesi.
    
    In alternativa, si possono vedere le rappresentazioni come $\bC[G]$-moduli, dove $\bC[G]$ è l'anello delle combinazioni $\bC$-lineari di elementi di $G$.
    
    \begin{mydef}
     Si definisce \myname{grado} di una rappresentazione $\rho$
     \[\deg \rho := \dim V_\rho\]
    \end{mydef}

    
    Sia ora $[\rho_g]_\cB$ la \myname{matrice associata} all'applicazione lineare $\rho_g$ in base $\cB$. Allora $[\rho_g]$ è quadrata, di ordine $\deg \rho$, invertibile ($\det [\rho_g]\ne 0$) e vale $[\rho_g] [\rho_h]=[\rho_{gh}]$. Inoltre, se $[\rho_g]_i^j$ è il coefficiente di $[\rho_g]$ di riga $i$ e colonna $j$, allora vale
    \[
     [\rho_{gh}]_i^k=\sum_j [\rho_g]_i^j [\rho_h]_j^k
    \]

    Dato che per gruppi finiti $[\rho_g]^n$ deve fare l'identità per $n=\abs G$, allora il suo polinomio minimo divide $x^n-1$, e visto che non ha fattori ripetuti $[\rho_g]$ è diagonalizzabile, con solo radici $n$-esime dell'unità sulla diagonale. 
    
    \begin{mydef}
      Date $\rho,\sigma$ due rappresentazioni di $G$ su $V_\rho,V_\sigma$ rispettivamente, si dice \myname{omomorfismo di rappresentazioni} un omomorfismo $\phi$ di spazi vettoriali $V_\rho \rightarrow V_\sigma$ tale che $\rho(g) \circ \phi = \phi \circ \sigma(g)$. 
      In altre parole, deve far commutare il seguente diagramma
      \[
       \begin{diagram}
	V_\rho         & \rTo^{\phi}  & V_\sigma\\
	\dTo<{\rho(g)} &           	 & \dTo>{\sigma(g)}\\
	V_\rho         & \rTo^{\phi}  & V_\sigma
       \end{diagram}
      \]
       
    Analogamente, si definisce \myname{endomorfismo} di $\rho$ un omomorfismo da $\rho$ in $\rho$, e \myname{isomorfismo di rappresentazioni} un omomorfismo che è un isomorfismo di spazi vettoriali.
    \end{mydef}
    
    Pensate come $\bC[G]$-moduli, allora gli omomorfismi di rappresentazioni coincidono con i morfismi di $\bC[G]$-moduli.
    
    Come al solito, identificheremo le rappresentazioni isomorfe, senza scrivere tutte le volte \emph{a meno di isomorfismo}.
    
    Dette $R_g$ e $S_g$ le matrici associate alle applicazioni lineari $\rho_g$ e $\sigma_g$ rispettivamente, se le due rappresentazioni sono isomorfe, allora esiste una matrice $T$ invertibile tale che
    \[
     R_g = T\inv S_g T \qquad \forall g\in G
    \]
    Quindi le matrici analoghe sono coniugate attraverso un'unica matrice invertibile.
        
    \begin{myexample}[Rappresentazione banale]
     Dato un qualsiasi gruppo $G$ e un qualsiasi spazio vettoriale $V$, una sua rappresentazione possibile è quella banale $g \mapsto \id$.
    \end{myexample}
    \begin{myexample}[Rappresentazione regolare]
     Sia $G$ un gruppo finito, e sia $V$ uno spazio vettoriale con base indicizzata da $G$ (ci starebbe una digressione sulla definizione di base). La rappresentazione regolare $\Reg$ è quella rappresentazione che associa a ogni elemento del gruppo l'azione di \emph{moltiplicazione a sinistra} sulla base, ossia $\Reg_g: e_h \mapsto e_{gh}$.
     
     Alternativamente, posso vedere $V$ come lo spazio $\mathbb C[G]$ delle funzioni da $G$ in $\mathbb C$ (l'indentificazione è quella che manda il vettore $\sum_i a_ie_{g_i}$ nella mappa $g_i \mapsto a_i$). In tal caso la rappresentazione regolare diventa
     \[
     \Reg_g(f): x \mapsto  f ( g\inv x) 
     \]
     
     Questa rappresentazione è particolarmente importante perché coincide con $\bC[G]$ visto come $\bC[G]$-modulo, che è sostanzialmente la prima definizione.
     
     Vedremo l'importanza di questa rappresentazione.
     \end{myexample}
     \begin{myexample}[Rappresentazione per permutazione di un insieme]
      Più in generale, se ho un'azione di $G$ su un insieme $X$, posso considerare $V$ con $X\rightarrow V$ una base, e costruire la rappresentazione che permuta la base tramite l'azione su $X$. Anch'essa è una rappresentazione.
    \end{myexample}
  
    \begin{myexample}[Rappresentazioni di $\Cyc_n$]
      Ho esattamente $n$ possibilità per $\chi_\rho$. Infatti, se $g$ genera $\Cyc_n$, posso scegliere $\chi_\rho(g)=\zeta^i$ per $i=0,1\dots n-1$, dove $\zeta$ è una radice primitiva dell'unità.
     
      Posso ora scrivere
      \[
       V=\bigoplus_{\lambda=\zeta^i}V_\lambda
      \]
      dove i $V_\lambda$ sono gli autospazi dell'applicazione $\rho_(g)$ relativi all'autovalore $\lambda$.
      
      Se $\rho$ è una rappresentazione in $V$, e $\sigma$ in W, allora $\phi$ è un omomorfismo da $\rho$ in $\sigma$ se e solo se $\phi(V_\lambda)\subseteq \phi(W_\lambda)$ per ogni $\lambda$.
      
      \begin{proof}
       Perchè sia un omomorfismo di rappresentazione, chiaramente gli autospazi di $V$ devono andare negli autospazi di $W$. Inoltre, visto che posso scegliere una base di autovettori (le immagini di una rappresentazione di un gruppo finito sono diagonalizzabili), mi basta che soddisfi le proprietà su una base.
      \end{proof}


    \end{myexample}
    
  \subsection{Operazioni tra rappresentazioni}
    Vediamo quali operazioni si possono definire tra le rappresentazioni.
    
    \begin{mydef}[Somma di rappresentazioni]
     Siano $\rho, \sigma$ due rappresentazioni di $G$ in $V_\rho,V_\sigma$ rispettivamente. Si definisce la \myname{somma di rappresentazioni} $\rho+\sigma$ come la rappresentazione di $G$ in $V_\rho\oplus V_\sigma$ tale che 
     \[
      (\rho+\sigma)_g(u+v)=\rho_g(u)+\sigma_g(v)\qquad \forall u\in V_\rho, v\in V_\sigma
     \]
    \end{mydef}
    
    Matricialmente $(\rho+\sigma)_g$ si rappresenta come
    \[
     \left[\begin{array}{c|c}
	    \rho_g & 0 \\
	    \hline
	    0 & \sigma_g
           \end{array}
     \right]
    \]
    dove ovviamente si intende che la base ha i primi vettori in $V_\rho$, i secondi in $V_\sigma$.
    
    Inoltre per come è definito il grado vale $\deg(\rho+\sigma)=\deg\rho+\deg\sigma$.
    
    \begin{mydef}
     Un sottospazio $W$ di $V_\rho$ si dice $G$-invariante se per ogni $g\in G$ vale $\rho_g(W)\subseteq W$.
    \end{mydef}

    \begin{mydef}
     Si dice \myname{sottorappresentazione} di $\rho$ la restrizione dei $\rho_g$ a un sottospazio vettoriale $G$-invariante. Nel linguaggio dei moduli si parla di sottomodulo.
    \end{mydef}
    
    \begin{myexample}
      Data la rappresentazione regolare $\Reg$, allora il sottospazio generato da $\sum_{g\in G} e_g$ è $G$-invariante, e la sottorappresentazione indotta è quella banale.
    \end{myexample}
       
    Ora invece, data una rappresentazione su $V$, vediamo come costruirne una sul duale $V^*$.
    \begin{mydef}
     Sia $\rho$ una rappresentazione di $G$ su $V$. Dato $f\in V^*$ e $v\in V$, sia ora $\scalar fv$ la dualità (è solo un modo figo per chiamare l'applicazione $\scalar fv \mapsto f(v)$). Definiamo la \myname{rappresentazione duale} $\rho^*$ come l'unica rappresentazione tale che:
     \[
      \scalar{\rho^*_g(f)}{\rho_g (v)}=\scalar fv
     \]
    \end{mydef}
    
    In altre parole, $\rho^*_g$ è l'applicazione \myname{trasposta} di $\rho_g\inv$.

    Il fatto che io usi l'inverso è perché l'applicazione trasposta inverte l'ordine delle composizioni, mentre noi vogliamo un isomorfismo: quindi mettendo l'inverso l'ordine torna magicamente a essere quello giusto.
    
    Oltre alla somma, abbiamo anche un prodotto tra rappresentazioni. Esso è definito come segue. 
    
    \begin{mydef}
     Si dice prodotto tra due $G$-rappresentazioni $\rho, \sigma$ la $G$-rappresentazione su $V_\rho \tensor V_\sigma$  
    \end{mydef}


    Ora siamo pronti a dare la definizione di prodotto di rappresentazioni.

    \begin{mydef}[Prodotto di rappresentazioni]
      Siano $\rho,\sigma$ due rappresentazioni su $V_\rho,V_\sigma$. Si definisce il prodotto $\rho\sigma$ come la rappresentazione su $V_\rho \otimes V_\sigma$ che soddisfa
      \[
       (\rho\sigma)_g = \rho_g \otimes \sigma_g
      \]
    \end{mydef}


  
  \subsection{Rappresentazioni irriducibili e Schur}
  
  Iniziamo con un risultato prelimnare.
  
    \begin{mytheorem}\label{Th:SupplInv}
     Sia $\rho$ una rappresentazione su $V$, e sia $W$ un sottospazio $G$-invariante. Allora esiste un supplementare $W_0$ anch'esso $G$-invariante.
    \end{mytheorem}
    
    \begin{proof}
     Sia $\pi$ una qualsiasi proiezione di $V$ su $W$, e sia $\pi_0$ la proiezione pesata data da
     \[
      \pi_0=\frac1{\abs G} \sum_{g\in G} \rho_g \circ \pi \circ \rho_g\inv
     \]
     Dato che $\pi$ lascia fisso $W$ allora anche $\pi_0$ lo lascia fisso (sto usando che $\rho_g$ stabilizza $W$). Inoltre $\pi_0(V) \subseteq W$. Quindi anch'essa è una proiezione con $\Ker \pi_0=W_0$ . Inoltre $\pi_0$ commuta con i $\rho_g$, come si vede calcolando $\rho_g \circ \pi_0 \circ \rho_g\inv$.
     
     Quindi se $w\in W_0$, allora $\pi_0 (\rho_g(w))=\rho_g(\pi_0(w))=0$, quindi $W_0$ è $G$-invariante ed è facile verificare che è anche un supplementare.
    \end{proof}
    \begin{myobs}
     Se su $V$ fosse definito un prodotto hermitiano, allora il prodotto hermitiano dato da $\sum_{g\in G}\herm {\rho_g(x)}{\rho_g(y)}$ è invariante per $G$, quindi si può facilmente verificare che $W^\perp$ è $G$-invariante, abbiamo così una dimostrazione alternativa del teorema \ref{Th:SupplInv}.
     
     Inoltre, dato che rispetto al prodotto hermitiano $G$ è invariante, significa che i $\rho_g$ sono ortogonali rispetto a una base ortonormale, e quindi sono matrici unitarie.
    \end{myobs}

    Ogniqualvolta abbiamo una sottorappresentazione di $\rho$, siamo quindi in grado di spezzare $\rho$ in somma di due sottorappresentazioni più piccole. 
 
    Data una rappresentazione, possiamo reiterare il procediemnto finché non è più possibile trovare sottorappresentazioni non banali.
    
    \begin{mydef}
      Una rappresentazione che non ammette sottorappresentazioni non banali si dice irriducibile.
    \end{mydef}
    
    Banalmente, tutte le rappresentazioni di grado 1 sono irriducibili, ma in generale non sono le uniche.
    
    Possiamo quindi decomporre una rappresentazione fino a quando gli addendi non sono tutti irriducibili.
    
    Ci piacerebbe affermare che la decomposizione in irriducibili è unica (dove unica è inteso come al solito a meno dell'ordine). Tuttavia non è così banale dimostrarlo. Per farlo ci serve che se possiamo immergere una rappresentazione irriducibile in una somma, allora possiamo immergerla in almeno uno dei fattori. (Sì, vogliamo in un qualche senso che irriducibile $\Rightarrow$ primo)
    
    Ci viene in aiuto il Lemma di Schur.
    
    \begin{mytheorem}[Lemma di Schur]
     Siano $\rho,\sigma$ due rappresentazioni irriducibili, e sia $\Phi$ un omomorfismo. Allora o $\Phi \equiv 0$ oppure $\Phi$ è un isomorfismo.
    \end{mytheorem}
    \begin{proof}
     Notiamo che $\Ker \Phi$ è banale oppure è tutto $V_\rho$, dato che $\rho$ è irriducibile. Nel secondo caso quindi $\Phi\equiv 0$, altrimenti si vede che analogamente $\Im \Phi$ è tutto $V_\sigma$. Quindi $\Phi$ è un isomorfismo.
    \end{proof}
    
    Ora due facili corollari.
    
    \begin{mycor}
     Sia $\rho$ irriducibile, e sia $\Phi: \rho \rar \rho$ un endomorfismo di rappresentazione. Allora $\Phi$ è una moltiplicazione per uno scalare. 
    \end{mycor}
    \begin{proof}
      Sia $\lambda$ un autovalore di $\Phi$: allora $\Phi-\lambda\id$ ha $\Ker$ non banale e quindi è identicamente nulla.
    \end{proof}

    \begin{mycor}
     Date $\rho,\sigma$ irriducibili, e $\Phi: V_\rho \rightarrow V_\sigma$ lineare, sia $\bar \Phi = \frac 1{\abs G} \sum_{g\in G} \sigma_g\inv \Phi \rho_g$. Allora
     \begin{itemize}
      \item Se $\rho \not \isom \sigma$ allora $\bar \Phi\equiv 0$;
      \item Se $\rho = \sigma$, allora $\bar \Phi = \frac{\Tr(\Phi)}{\deg \rho}\id$.
     \end{itemize}
    \end{mycor}
    \begin{proof}
     Deriva tutto dal lemma di Schur. Il fatto che lo scalare si $\frac{\Tr \Phi}{\deg \rho}$ viene dal fatto che $\Tr \bar \Phi = \Tr \Phi$ (basta fare il conto) e che $\Tr \bar \Phi = \lambda \deg \rho$.
    \end{proof}


    Adesso possiamo concludere il claim precedente.
    \begin{myprop}
     Ogni rappresentazione si può scrivere in maniera unica come somma di rappresentazioni irriducibili.
    \end{myprop}
    \begin{proof}
     Siano $\rho = \rho_1 + \rho_2 + \dots + \rho_n = \sigma_1 + \dots +\sigma_m$ due decomposizioni in irriducibili della stessa rappresentazione. Prendiamo $\sigma_1$ e la immergiamo in modo canonico in $\rho$. A questo punto, restringendosi ai $\rho_i$, abbiamo degli omomorfismi da $\sigma_1$ in $\rho_i$, che non possono essere tutti banali. Quindi per il lemma di Schur $\sigma_1\isom \rho_i$ per qualche $i$. La conclusione per induzione è immediata. 
    \end{proof}
    
    \begin{mydef}
     Data una rappresentazione $\rho$, si dice componente isotopica una sottorappresentazione della forma $n_i\rho_i$, con $n_i$ massimo possibile e $\rho_i$ irriducibile.
    \end{mydef}

    Le componenti isotopiche sono importanti perché sono caratteristiche.
    
    \begin{myprop}
     Sia $\rho$ una rappresentazione, e sia $\sigma$ una sua componente isotopica. Sia inoltre $\phi$ un automorfismo di $\rho$. Allora $\phi(\sigma)=\sigma$.
    \end{myprop}

    \begin{proof}
     Considero $\phi(\sigma)$. Poiché sulle altre rappresentazioni irriducubili deve essere l'applicazione nulla per il lemma di Schur, allora per questioni di dimensione deve essere mandata in $\sigma$.
    \end{proof}
  
  \section{Caratteri}
    
    \begin{mydef}
     Si dice \myname{carattere} di una rappresentazione $\rho$ l'applicazione $\chi_\rho: G \rightarrow C^*$ definita da 
     \[
      \chi_\rho(g)=\Tr \rho(g)
     \]
    \end{mydef}
    
    \begin{Achtung}
      Il carattere \underline{NON} è un'omomorfismo da $G$ in $C^*$! Lo è se e solo se $\deg \rho = 1$. 
    \end{Achtung}

    \begin{myprop}
      Il carattere soddisfa le seguenti:
      \begin{enumerate}
       \item $\chi_\rho(e)=\deg\rho$
       \item $\chi_\rho(g\inv)=\conj{\chi_\rho(g)}$
       \item $\chi_\rho(hgh\inv)=\chi_\rho(g)$
      \end{enumerate}

    \end{myprop}
    \begin{proof}
     La 1 è ovvia, visto che $\rho_e= \id_n$, dove $n=\deg \rho$.
     
     La 2 viene dal fatto che, essendo $\rho_g$ diagonalizzabile con autovalori di norma $1$, e dato che la traccia è la somma degli autovalori, allora
     \[
      \Tr\rho_g\inv = \sum_i \lambda_i\inv = \sum_i \conj{\lambda_i} = \conj{\sum_i \lambda_i} = \conj{\Tr\rho_g} 
     \]
     da cui quello che volevamo.
     
     La 3 invece deriva dal fatto che se $g$ e $g'$ sono coniugati, allora anche $\rho_g$ e $\rho_{g'}$ lo sono, e la traccia è invariante per coniugio. Ogni funzione che soddisfa la 3 si chiama \myname{funzione di classe}.
    \end{proof}
    
    Ci chiediamo se il carattere identifica le rappresentazioni, ossia se rappresentazioni diverse hanno caratteri diversi.
    Intanto però il carattere distingue il grado di una rappresentazione, che è dato da $\deg \rho = \chi_\rho(e)$.
 
    \begin{mylemma}
    I caratteri godono delle seguenti proprietà:
      \begin{itemize}
      \item $\chi_{\rho+\sigma}=\chi_\rho+\chi_\sigma$     
      \item $\chi_{\rho\otimes\sigma}=\chi_\rho\cdot\chi_\sigma$
      \item $\chi_{\rho^*} = \conj{\chi_\rho}$
      \end{itemize}
    \end{mylemma}
    \begin{proof}
     Per la rappresentazione duale vale 
     \[
      \chi_{\rho^*}(s)=\Tr (\trasp\rho_{s\inv})=\Tr (\rho_s\inv)
     \]
     Dato che la traccia è la somma degli inversi degli autovalori, e questi hanno modulo 1, allora otteniamo $\conj{\chi_\rho}$. 

    \end{proof}

    
    \subsection{Prodotto hermitiano}
    Introduciamo un prodotto interno su $\mathbb C^{(G)}$ (le funzioni da $G$ in $C$), dato da 
    \[
     \herm fg = \frac 1{\abs G} \sum_{s\in G} f(s)\conj{g(s)}
    \]
    
    Grazie a questo prodotto possiamo effettuare delle proiezioni.
    
    \begin{mylemma}
     Consideriamo $\rho$ una G-rappresentazione, e sia $\id$ la rappresentazione banale di grado 1 (irriducibile). Allora 
     \[
      \herm \rho\id = \frac 1{\abs G}\sum_{g\in G} \chi_\rho(g) = \dim V_\rho^G
     \]    
    \end{mylemma}
    \begin{proof}
     Sappiamo che per definizione
     \[
      \herm \rho\id = \frac 1{\abs G}\sum_{g\in G} \chi_\rho(g) = \frac 1{\abs G}\sum_{g\in G} \Tr(\rho(g)) 
     \]
     Per la linearità otteniamo $\Tr\left(\frac 1{\abs G}\sum_{g\in G}\rho(g)\right)$. Sia quindi $T=\frac 1{\abs G}\sum_{g\in G}\rho(g)$.
     
     Sia $v \in V^G_\rho$, allora $T(v)=v$. Inoltre per ogni $v$ vale che $T(v) \in V^G_\rho$ (si vede dal conto). Quindi abbiamo la tesi.
     
    \end{proof}
    
    Costruiamo ora un modo alternativo per esprimere questo prodotto hermitiano. Ci serve la costruzione della rappresentazione sugli omomorfismi.
    
    \begin{mydef}
     Siano $\rho, \sigma$ due rappresentazioni di $G$ su $V_\rho,V_\sigma$. Allora costruiamo una rappresentazione $\tau$ su $\Hom(V_\rho,V_\sigma)$ (come spazio vettoriale) definita da 
     \[
      \tau_g (\phi) = \sigma_g \circ \phi \circ \rho_g\inv
     \]
    \end{mydef}
    
    Per definizione, la rappresentazione su $\Hom(V_rho,V_sigma)$ fa commutare il seguente diagramma:
      \[
       \begin{diagram}
	V_\rho         & \rTo^{\phi}  & V_\sigma\\
	\dTo<{\rho(g)} &           	 & \dTo>{\rho(g)}\\
	V_\rho         & \rTo^{\tau_g(\phi)}  & V_\sigma
       \end{diagram}
      \]
    
    
    \begin{myprop}
     Esiste un isomorfismo canonico tra $\Hom (V_\rho,V_\sigma)$ e $V_\rho^* \tensor V_\sigma$ (se $V_\rho, V_\sigma$ hanno dimensione finita, altrimenti è falso).
    \end{myprop}
    
    \begin{proof}
     \`E una verifica.
    \end{proof}
    
    Noi abbiamo costruito una rappresentazione su $\Hom(V_\rho,V_\sigma)$, ma non tutti sono omomorfismi di rappresentazioni: lo sono infatti solo quelli fissati da $G$ (basta guardare il diagramma). Dato che $\chi_\tau = \conj{\chi_\rho}\chi_\sigma$ per le proprietà del prodotto tensore e della rappresentazione duale, allora vale per il lemma precedente
    \[
     \dim \Hom(\rho,\sigma) = \dim \Hom(V_\rho,V_\sigma)^G = \herm {\chi_\tau}\id = \herm{\chi_\sigma}{\chi_\rho}
    \]
    
    Notiamo che visto che è un numero intero, allora posso scambiare i due fattori nel prodotto hermitiano, e ottengo
    \[
     \herm{\chi_\rho}{\chi_\sigma} = \dim \Hom(\rho,\sigma)
    \]


    
    



   \subsection{Relazioni di ortogonalità}
    \begin{mytheorem}[Teorema di ortogonalità dei caratteri]
     Siano $\rho,\sigma$ due rappresentazioni irriducibili. Allora
     \[
      \herm {\chi_\rho} {\chi_\sigma} = \begin{cases}
                           1 \mbox{ se } \rho \isom \sigma \\
                           0 \mbox{ se } \rho \not\isom \sigma
                          \end{cases}
     \]
    \end{mytheorem}
    \begin{proof}
     \[
      \herm {\chi_\rho}{\chi_\sigma}=\dim \Hom(\rho,\sigma)
     \]
     e quindi con il lemma di Schur ho la tesi.
    \end{proof}
    
    \begin{myprop}\label{pr:IrrCount}
     Sia $\rho$ una rappresentazione decomposta in irriducibili. Allora il numero di addendi isomorfi a $\sigma$, con $\sigma$ irriducibile, è pari a $\herm{\chi_\rho}{\chi_\sigma}$.
    \end{myprop}

    In particolare, da questo deriva che due rappresentazioni con lo stesso carattere sono isomorfe.
    
    \begin{mytheorem}[Criterio di irriducibilità]
     Una rappresentazione $\sigma$ è irriducibile se e solo se $\herm\sigma\sigma=1$.
    \end{mytheorem}

   \subsection{Carattere della rappresentazione regolare}
    Sia $G$ un gruppo e sia $\Reg$ la sua rappresentazione regolare. Vogliamo indagare come si decompone $\Reg$ in somma di irriducibili. Sia quindi
    \[
     \Reg = \sum_i n_i \rho_i
    \]
    con $n_i \in \mathbb N$. Sia inoltre $\chi_R$ il carattere di $\Reg$ e $\chi_i$ il carattere dei $\rho_i$.
      
    \begin{myprop}
     Il carattere della rappresentazione regolare è
      \[
      \chi_R(g) = \abs G \cdot \delta_{ge}
      \]
     dove $\delta_{ij}$ è la \myname{delta di Kronecker}.
    \end{myprop}
    
    \begin{proof}
      Sappiamo che la matrice associata a $\Reg_g$ è una matrice di permutazione, e gli elementi sulla diagonale sono $1$ se $g=e$, $0$ altrimenti. Visto che il carattere è la somma degli elementi sulla diagonale, segue la tesi.
    \end{proof}
    
 
    
    Sorprendentemente, siamo in grado di determinare esplicitamente gli $n_i$.
    \begin{myprop}
     Ogni rappresentazione irriducibile $\rho_i$ di $G$ è contenuta $n_i$ volte in $\Reg$.
    \end{myprop}
    
    \begin{proof}
     Basta applicare la Proposizione \ref{pr:IrrCount}:
     \[
      \herm{\chi_R}{\chi_i} = \frac1{\abs G}\sum_{g\in G} \chi_R(g)\conj{\chi_i(g)} = \frac1{\abs G}\chi_R(e)\conj{\chi_i(e)} = n_i
     \]

    \end{proof}

    Vediamo anche una dimostrazione alternativa, che si basa sul seguente lemma:
    \begin{mylemma}
      Sia $G$ un gruppo, e sia $\rho$ una rappresentazione, e $\Reg$ la sua rappresentazione regolare. Allora, fissato $v\in V_\rho$, esiste un unico omomorfismo di rappresentazioni $\phi: \Reg \rightarrow \rho$ tale che $\phi(e_1)=v$.
    \end{mylemma}
    \begin{proof}
      Se $\phi$ è un omomorfismo di rappresentazione, allora deve valere 
      \[
      \phi(e_g)=\phi \circ \Reg_g (e_1) = \rho_g \circ \phi (e_1) = \rho_g(v)
      \]
      e quindi se esiste è unica. \`E facile verificare che questo omomorfismo rispetta le ipotesi.
    \end{proof}
    
    La dimostazione diventa ora immediata:
    \begin{proof}
     Per quanto visto nel lemma, vale $\dim \Hom(R,\rho_i) = \dim V_{\rho_i}$. Quindi
     \[
      \herm{\chi_R}{\chi_i}= \dim \Hom(R,\rho_i) = \dim V_{\rho_i} = n_i
     \]
     e ottengo la tesi.
    \end{proof}
    
    Questo teorema ha importantissime conseguenze, la cui più evidente è la seguente:
    \begin{myprop}
     Con le notazioni precedenti vale $\sum_i n_i^2 = \abs G$ e, se $g\ne e$, $\sum_i n_i \chi_i(g)=0$
    \end{myprop}
    \begin{proof}
     Per definizione vale $\sum n_i \chi_i(g) = \chi_R(g)$. Prendendo $g=e$ ottengo la prima proposizione, per $g\ne e$ ottengo invece la seconda.
    \end{proof}

    \begin{mytheorem}
     I caratteri delle rappresentazioni irriducibili di $G$ formano una base ortonormale delle funzioni classe $\class G$.
    \end{mytheorem}
    
    \begin{proof}
     C'è un po' da faticare.
    \end{proof}

    
    \begin{mytheorem}
     Le rappresentazioni irriducibili di $G$ sono tante quante le classi di coniugio.
    \end{mytheorem}

    \begin{proof}
     Visto che sulle funzioni di classe ho la base canonica costruita sulle classi di coniugio, ma ho anche la base formata dalle rappresentazioni irriducibili, come basi di uno spazio vettroriale devono avere la stessa cardinalità.
    \end{proof}

    \section{Tabella dei caratteri}
    
    Dato un gruppo $G$, possiamo costruire la sua \myname{tabella dei caratteri} fatta come segue:
    \begin{itemize}
     \item Su ogni colonna mettiamo una classe di coniugio del gruppo;
     \item su ogni riga mettiamo una rappresentazione irriducibile del gruppo;
     \item all'incrocio tra la rappresentazione $\rho$ e la classe di coniugio $C$ inseriamo il valore di $\chi_\rho(g)$ con $g\in C$ (sto usando il fatto che il carattere è invariante di coniugio).
    \end{itemize}

    Per quanto abbiamo visto la tabella è \emph{quadrata} (ho tante classi di coniugio quante rappresentazioni irriducibili).
    
    Per le relazioni di ortogonalità dei caratteri, sappiamo che le righe sono tutte \emph{ortonormali} (dove bisogna sempre ricordarsi di fare la media pesata sulla cardinalità della classe di coniugio quando si effettua il prodotto hermitiano).
    
    Inoltre vale anche la seguente:
    \begin{myprop}[Ortogonalità delle colonne]
     Se $\chi_i$ sono le rappresentazioni irriducibili di $G$, e $g,h\in G$ non coniugati, e $c(g)$ la cardinalità della classe di coniugio di $g$, allora 
     \begin{align*}
	\sum_i \abs{\chi_i(g)}^2 = \frac {\abs G}{c(g)}\\
	\sum_i \chi_i(g)\conj{\chi_i(h)} = 0
     \end{align*}
    \end{myprop}

    \begin{myexample} [Tabella dei caratteri di $Q_8$]
     \[
      \begin{array}{|c|ccccc|}
      \hline
       Q_8    & \{1\} & \{-1\} & \{\pm i\} & \{\pm j\} & \{\pm k\} \\ \hline
       Id     &   1   &    1   &     1     &     1     &     1     \\ 
       \rho_i &   1   &    1   &     1     &    -1     &    -1     \\
       \rho_j &   1   &    1   &    -1     &     1     &    -1     \\
       \rho_k &   1   &    1   &    -1     &    -1     &     1     \\
       \rho_2 &   2   &   -2   &     0     &     0     &     0     \\ \hline
      \end{array}
     \]
     
     
    \end{myexample}


\iffalse 
  \section{Forma hermitiana, ortogonalità, rappresentazioni irriducibili}
    Sia $h_0$ un prodotto interno (forma hermitiana definita positiva) in $V\times V$, e definiamo 
    \[
      h(v,w)=\frac1{\abs G}\sum_{g\in G}h_0\left(\rho_g(v),\rho_g(w)\right) 
    \]
    In questo modo in $\rho_g$ sono tutte applicazioni lineari unitarie.
    
    \begin{myexample}
     Data una rappresentazione $\rho$ su $V$, indichiamo con $V^G$ il sottospazio dei punti lasciati fissi da tutti i $\rho_g$. In particolare $V^G$ è $G$-invariante e quindi ho ottenuto una sottorappresentazione (banale). 
    \end{myexample}
    \begin{myexample}
     Sia $\lambda$ un omomorfismo da $G$ in $C^*$. Possiamo definire, generalizzando la nozione di autospazio vista ad Algebra lineare, l'autospazio relativo a $\lambda$ come il sottospazio di $V_\rho$ costituito dai vettori $v$ che soddisfano 
     \[
      \rho_g(v)=\lambda(g)\cdot v
     \]

     Notiamo che se $\lambda \equiv 1$, allora $V_\lambda=V^G$. Inoltre, se pensiamo a $\lambda$ come una rappresentazione di grado 1, allora 
     \[	
      \restr\rho{V_\lambda}= \overbrace{\lambda + \lambda + \lambda + \dots + \lambda}^{\mbox{\tiny come somme di rappresentazioni!}}=\dim V_\lambda \cdot \lambda
     \]     
    \end{myexample}
\fi
  \section{Potenza simmetrica ed esterna}
  
    \begin{mydef}[Quadrato simmetrico e alternante]
     Sia $\rho$ una rappresentazione su $V$. Prendiamo lo spazio $V\otimes V$, e consideriamo l'automorfismo $\theta$ tale che 
     \[
      \theta(e_i \tensor e_j) = e_j \tensor e_i
     \]
     
     $V\otimes V$ si decompone quindi nella somma del quadrato simmetrico $S^2V$ dei vettori fissati da $\theta$, e nel quadrato alternante $\Lambda^2V$ dei vettori tali che $\theta(z) = -z$. Poichè essi sono $G$-invarianti (tramite la rappresentazione $\sigma^2$) allora essi definiscono due sottorappresentazioni.
    \end{mydef}
    
    \begin{myexample}
     Sia $V=\mathbb C^n$. Possiamo pensare $V\otimes V$ come $\mathcal M_n(\mathbb C)$, dove $v \tensor w = v\trasp w$. In questo caso, i quadrati simmetrici e alternanti coincidono con le matrici simmetriche e antisimmetriche rispettivamente.
    \end{myexample}
    
    \begin{mydef}[Potenza esterna]
      Si dice potenza esterna $n$-esima $\Lambda^nV$  di uno spazio vettroriale $V$ lo spazio $V^{\tensor n}$ quozientato per il sottospazio generato dai $v_1 \tensor v_2 \tensor \dots \tensor v_n$ con $v_i=v_j$ per qualche $i\ne j$.  
    \end{mydef}
    
    Detto in maniera più comprensibile, è l'insieme generato dagli elementi scritti come $v_1 \wedge v_2 \wedge \dots \wedge v_n$ dove scambiando una coppia di componenti l'intero prodotto cambia segno.
    
    \begin{Achtung}
     Il prodotto $v_1 \wedge v_2 \wedge v_3$ non va pensato in maniera ``associativa'' (come $(v_1 \wedge v_2) \wedge v_3$), perché non ha senso!
    \end{Achtung}

    Data una base $v_1,v_2,\dots,v_n$ di $V$, possiamo prender come base di $\Lambda^mV$ gli elementi della forma $v_{i_1},v_{i_2},\dots,v_{i_m}$ con $i_1<i_2<\dots<i_m$. \`E quindi evidente che $\dim \Lambda^mV=\binom nm$.    
     
    \begin{mydef}[Potenza simmetrica]
      Si dice potenza simmetrica $n$-esima $S^nV$  di uno spazio vettroriale $V$ lo spazio $V^{\tensor n}$ quozientato per il sottospazio generato dai $v_1 \tensor v_2 \tensor \dots \tensor v_n - v_{\sigma(1)} \tensor v_{\sigma(2)} \tensor \dots \tensor v_{\sigma(n)}$, dove $\sigma$ è una qualsiasi permutazione degli indici $\{1,2,\dots,n\}$.  
    \end{mydef}

    Anche qui, possiamo pensare la potenza simmetrica come il prodotto tensore in cui scambiando le componenti il prodotto rimane invariato.
    
    Analogamente a prima, una base per $S^mV$, con $\dim V=n$, sono i vettori della forma  $v_{i_1},v_{i_2},\dots,v_{i_m}$ con $i_1\le i_2\le \dots \le i_m$. Il conto combinatorico ci dice che $\dim S^mV = \binom{n+m-1}m$.

    
    Ora siamo pronti e mettere una rappresentazione su potenza esterna e simmetrica.
    
    
    
    \begin{mydef}
     Si dice potenza esterna di una rappresentazione $\rho$ la rappresentazione su $\Lambda^m V_\rho$ dove
     \[
      \Lambda^m\rho_g: v_1 \wedge v_2 \wedge \dots \wedge v_n \mapsto \rho_g(v_1) \wedge \rho_g(v_2) \wedge \dots \wedge \rho_g(v_n)
     \]
     
     In modo completamente analogo si definisce la potenza simmetrica.

    \end{mydef}
    
    Precedentemente abbiamo definito potenza esterna e simmetrica in modo astratto, ma si possono anche vedere come sottospazi della potenza tensoriale, e le relative rappresentazioni come sue sottorappresentazioni.
    
    \begin{myprop}
     Sia $\rho$ una rappresentazione su $V_\rho$, e sia $\rho^m$ la rappresentazione su $V_\rho^{\tensor m}$. Allora valgono le seguenti: 
     \begin{eqnarray*}
      &S^m\rho \isom \Span{\left\{\sum_\sigma v_{\sigma(1)}\tensor v_{\sigma(2)} \tensor \dots \tensor v_{\sigma(m)}:v_i \in V\right\}}\\
      &\Lambda^m\rho \isom \Span{\left\{\sum_\sigma \sgn(\sigma) v_{\sigma(1)}\tensor v_{\sigma(2)} \tensor \dots \tensor v_{\sigma(m)}:v_i \in V\right\}} 
     \end{eqnarray*}

    \end{myprop}

    \begin{proof}
     Basta far vedere che, per $S^m\rho$, l'applicazione
     \[
      v_1 \tensor \dots \tensor v_m \mapsto \frac1{m!} \sum_\sigma v_{\sigma(1)}\tensor v_{\sigma(2)} \tensor \dots \tensor v_{\sigma(m)}
     \]
     e, per $\Lambda^m\rho$, l'applicazione
     \[
      v_1 \tensor \dots \tensor v_m \mapsto \frac1{m!} \sum_\sigma \sgn(\sigma) v_{\sigma(1)}\tensor v_{\sigma(2)} \tensor \dots \tensor v_{\sigma(m)}
     \] sono ben definite, sono suriettive e hanno il nucleo giusto, e poi si può concludere per il teorema di omomorfismo. 
    \end{proof}
    
    

  
 
  \section{Rappresentazioni di gruppi particolari}
   Per costruire la tabella dei caratteri, dobbiamo costruire delle rappresentazioni da cui estrarre le irriducibili. Ci sono sostanzialmente due modi: il primo è inferendo sulla struttura del gruppo, la seconda è costruendo rappresentazioni su spazi vettroiali diversi (come le potenze esterne). In questa sezione ci occuperemo del primo metodo.
  
  \subsection{Gruppi abeliani}
   Le rappresentazioni dei gruppi abeliani sono particolarmente semplici. Vale infatti la seguente proposizione:
   \begin{myprop}
    Sia $G$ un gruppo, e siano $\rho_i$ le sue rappresentazioni irriducibili. Allora G è abeliano se e solo se tutte le $\rho_i$ hanno grado 1.
   \end{myprop}
    
   \begin{proof}
    Supponiamo che $G$ sia abeliano. Allora ho $\abs G$ classi di coniugio e pertanto altrettante rappresentazioni irriducibili. Dato che $\sum_i n_i^2 = \abs G$ segue $n_i = 1$.
    
    Viceversa, supponiamo che $G$ sia un gruppo le cui rappresentazioni irriducibili hanno grado 1. Consideriamo una rappresentazione $\rho$ fedele di $G$ (ad esempio quella regolare), quindi possiamo decomporla in irriducibili di grado 1. Questo significa che esiste una base in cui tutte le $\rho_g$ sono diagonali, e pertanto commutano. Dunque $\rho_g\rho_h = \rho_h\rho_g \Rightarrow \rho_{gh} = \rho_{hg}$ e per l'iniettività di $\rho$ ho finito.
   \end{proof}
  \subsection{Sottogruppi normali}
    Se il gruppo ha sottogruppi normali, possiamo ottenere gratuitamente delle rappresentazioni del gruppo conoscendo quelle di un gruppo più piccolo.
    
    \begin{myprop}
     Sia $N$ sottogruppo normale di $G$, e sia $\sigma$ una rappresentazione del quoziente $G/N$. Allora $\sigma$ si può estendere in modo naturale a rappresentazione $\rho$ di $G$, e in particolare le rappresentazioni del quoziente sono in relazione biunivoca con quelle di $G$ il cui $\Ker$ contiene $N$. Inoltre le irriducibili in $G/N$ sono irriducibili anche in $G$.
    \end{myprop}
    \begin{proof}
     Basta mandare mappare l'applicazione $\sigma_{gN}$ in $\rho_g$ assicurandosi che sia una buona definizione. E' simile alla corrispondenza biunivoca tra sottogruppi.
     Per quanto riguarda l'irriducibilità, basta vedere che, se $R\subset G$ è un insieme di rappresentanti delle classi laterali di $N$, allora 
     \[
      \frac{\abs{N}}{\abs{G}} \sum_{g\in R}\Tr \sigma_{gN}\conj{\Tr \sigma_{gN}} = \frac1{\abs G} \sum_{g\in R} \abs N \Tr \sigma_{gN}\conj{\Tr \sigma_{gN}} = \frac1{\abs G} \sum_{g\in G} \conj{\Tr \rho_{g}}
     \]
     quindi i due caratteri hanno la stessa norma.
    \end{proof}
    
    \begin{myexample} [Tabella dei caratteri di $Q_8$]
    Voglio costrure la tabella dei caratteri di $Q_8$. Ho 5 classi di coniugio, quindi 5 rappresentazioni. Una è l'identità. Per trovarne altre 3, posso pensare che $\{1,-1\}$ è normale, e quozientando ottengo $\Cyc_2 \times \Cyc_2$, che ha 3 rappresentazioni irriducibili non banali (scelgo quale dei 3 sottogruppi mandare nell'identità, e il resto andrà in $-1$). Sollevandole in $Q_8$, ottengo $\rho_i,\rho_j,\rho_k$. L'ultima rappresentazione, di grado 2, la ottengo per ortogonalità.
     \[
      \begin{array}{|c|ccccc|}
      \hline
       Q_8    & \{1\} & \{-1\} & \{\pm i\} & \{\pm j\} & \{\pm k\} \\ \hline
       Id     &   1   &    1   &     1     &     1     &     1     \\ 
       \rho_i &   1   &    1   &     1     &    -1     &    -1     \\
       \rho_j &   1   &    1   &    -1     &     1     &    -1     \\
       \rho_k &   1   &    1   &    -1     &    -1     &     1     \\
       \rho_2 &   2   &   -2   &     0     &     0     &     0     \\ \hline
      \end{array}
     \]
     
     
    \end{myexample}


  
  \subsection{Prodotto diretto}
   
   Vogliamo ora indagare come sono fatte le rappresentazioni di un prodotto diretto di gruppi, a partire dalle rappresentazioni sui singoli gruppi.
   
   Date due rappresentazioni $\rho$ di $G_1$, $\sigma$ di $G_2$, possiamo generalizzare il prodotto di rappresentazioni.
   \begin{mydef}
    Si definisce il \myname{prodotto tensoriale} di rappresentazioni la rappresentazione di $G_1\times G_2$ data da
    \[
     (\rho \tensor \sigma)(g_1,g_2) = \rho_{g_1} \tensor \rho_{g_2} 
    \]
   \end{mydef}

   \begin{myprop}
    Il carattere del prodotto tensoriale vale
    \[
     \chi_{\rho\tensor\sigma}(g_1,g_2) = \chi_\rho(g_1)\chi_\sigma(g_2)
    \] 
   \end{myprop}

   \begin{proof}
    Per le proprietà del prodotto tensore di spazi vettoriali, vale $\Tr(\rho_{g_1}\tensor \sigma_{g_2})= \Tr{\rho_{g_1}}\Tr{\sigma_{g_2}}$
   \end{proof}
   
   Abbiamo quindi ottenuto una rappresentazione di $G_1\times G_2$, ci chiediamo quando è irriducibile. 
   \begin{myprop}
    Le rappresentazioni $\sigma$ e $\rho$ sono irriducibili se e solo se $\rho \tensor \sigma$ è irriducibile.
    
    Inoltre tutte le rappresentazioni irriducibili di $G_1\times G_2$ sono della forma $\rho \tensor \sigma$, con $\rho,\sigma$ irriducibili.
   \end{myprop}
   \begin{proof}
    Facciamo il conto con il carattere di $\rho \tensor \sigma$.
    \begin{align*}
     \herm{\chi_{\rho\tensor\sigma}}{\chi_{\rho\tensor\sigma}} &= \frac1{\abs {G_1}\abs{G_2}}\sum_{g_1 \in G_1}\sum_{g_2\in G_2} \chi_\rho(g_1)\chi_\sigma(g_2)\conj{\chi_\rho(g_1)\chi_\sigma(g_2)} = \\
     &= \frac1{\abs {G_1}}\sum_{g_1 \in G_1} \chi_\rho(g_1)\conj{\chi_\rho(g_1)}\cdot\frac1{\abs {G_2}}\sum_{g_2\in G_2}\chi_\sigma(g_2)\conj{\chi_\sigma(g_2)}\\
     &= \herm{\chi_\rho}{\chi_\rho}\herm{\chi_\sigma}{\chi_\sigma}
    \end{align*}
    e ora si ha la tesi per il criterio di irriducibilità.
    
    Per il secondo punto invece, mostriamo che un qualsiasi carattere $f$ (funzione di classe) su $G_1\times G_2$, ortogonale a tutti i caratteri della forma $\chi_\rho(g_1)\chi_\sigma(g_2)$, è nullo. Quindi sia
    \[
     \sum_{g_1,g_2} f(g_1,g_2) \conj{\chi_\rho(g_1),\chi_\sigma(g_2)}=0
    \]
    
    Fissiamo $\sigma$, e sia $h(g_1)=\sum_{g_2} f(g_1,g_2)\conj{\chi_\sigma(g_2)}$. Allora
    \[
     \sum_{g_1}h(g_1)\conj{\chi_\rho(g_1)}=0 \qquad\qquad \forall \rho
    \]
    Poichè deve valere per ogni rappresentazione $\rho$, e $h$ è una funzione classe, allora deve essere $h\equiv 0$. Analogamente si conclude che $f \equiv 0$.


   \end{proof}

  \section{Coefficienti matriciali}
    \begin{mydef}
     Sia $\rho$ una rappresentazione di $G$ su $V_\rho$. Sia $\mathcal B$ una base di $V_\rho$, e sia $r_g$ la matrice associata a $\rho_g$.
     
     Si dice \myname{coefficiente matriciale} di posto $i,j$ l'applicazione da $G$ in $\mathbb C$ che associa a un elemento del gruppo la componente $[r_g]_{ij}$.
     
     Lo spazio generato da queste funzioni si dice \myname{spazio dei coefficienti matriciali} e si indica con $\mathcal M(\rho)$.
    \end{mydef}

 
  \section{Cose che non hanno ancora un posto}
   \subsection{Rappresentazione regolare con azione di $G\times G$}
   Sia $\mathbb C[G]$ 
  \section{Esercizi}
  \begin{myex}
   Consideriamo un $n$-agono regolare, con un numero complesso scritto su ogni vertice. A ogni passo sositiuisco ogni vertice con la media degli adiacenti. Come si comporta il problema asintoticamente?
   
   Consideriamo lo spazio vettoriale $\mathbb C^n$ dei numeri presenti sui vertici, e consideriamo la rappresentazione regolare di $\Cyc_n$ su $\mathbb C^n$ (che agisce sui vettori della base per rotazione). Sia inoltre $T$ l'applicazione lineare che manda ogni vertice nella media degli adiacenti.
   
   Visto che $T$ commuta con tutti i $\rho_g$, allora $T$ è anche un \myname{endomorfismo di rappresentazione}. DA FINIRE
  \end{myex}

\end{document}
